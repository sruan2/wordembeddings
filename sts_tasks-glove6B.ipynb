{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embeddings and textual similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we try to replicate the experimental results on textual similarity tasks from **A Simple but Tough-to-Beat Baseline for Sentence Embeddings** (Arora *et al*. 2017, https://openreview.net/pdf?id=SyK00v5xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Textual Similarity (STS) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [SemEval](http://alt.qcri.org/semeval2016/) data are obtained from the `datasets-sts` repo: https://github.com/brmson/dataset-sts\n",
    "\n",
    "`pysts` (included in this repo) can be used to load STS tasks data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./dataset-sts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysts\n",
    "from pysts.loader import load_sts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the headlines dataset of SemEval 2015:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0, s1, labels = load_sts(\"dataset-sts/data/sts/semeval-sts/2015/headlines.test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives two lists of lists of the sentences (`s0` and `s1`), and the corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3',\n",
       " 'Suspects',\n",
       " 'Taken',\n",
       " 'Into',\n",
       " 'Custody',\n",
       " 'in',\n",
       " 'Boston',\n",
       " 'Bombing',\n",
       " 'Case']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boston',\n",
       " 'police',\n",
       " 'say',\n",
       " '3',\n",
       " 'taken',\n",
       " 'into',\n",
       " 'custody',\n",
       " 'in',\n",
       " 'Marathon',\n",
       " 'bombing']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7999999999999998"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(min(labels))\n",
    "print(max(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, it excluded those pair of sentences that had not a label (can also use `skip_unlabeled=False`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0, s1, labels = load_sts(\"dataset-sts/data/sts/semeval-sts/2015/headlines.test.tsv\", skip_unlabeled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0, s1, labels = load_sts(\"dataset-sts/data/sts/semeval-sts/2015/headlines.test.tsv\", skip_unlabeled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe pre-trained word vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe - Global Vectors for Word Representation (https://nlp.stanford.edu/projects/glove/). Pre-trained word vectors have been downloaded (we use the 300-dimensional vectors trained on the 840 billion token Common Crawl corpus: http://nlp.stanford.edu/data/glove.840B.300d.zip), and converted to a dictionary for further usage:\n",
    "    \n",
    "    import pandas as pd\n",
    "    import zipfile\n",
    "    \n",
    "    z = zipfile.ZipFile(\"./glove.840B.300d.zip\")\n",
    "    glove = pd.read_csv(z.open('glove.840B.300d.txt'), sep=\" \", quoting=3, header=None, index_col=0)\n",
    "    glove2 = {key: val.values for key, val in glove.T.items()}\n",
    "    \n",
    "    import pickle\n",
    "    with open('glove.840B.300d.pkl', 'wb') as output:\n",
    "        pickle.dump(glove2, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "#z = zipfile.ZipFile(\"/Users/sherryruan/data/glove/glove.840B.300d.zip\")\n",
    "#glove = pd.read_csv(z.open('glove.840B.300d.txt'), sep=\" \", quoting=3, header=None, index_col=0)\n",
    "# change to glove.6B instead\n",
    "glove = pd.read_csv('/Users/sherryruan/data/glove/glove.6B/glove.6B.300d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "glove2 = {key: val.values for key, val in glove.T.items()}\n",
    "\n",
    "import pickle\n",
    "with open('/Users/sherryruan/data/glove/glove.6B/glove.6B.300d.pkl', 'wb') as output:\n",
    "    pickle.dump(glove2, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/sherryruan/data/glove/glove.6B/glove.6B.300d.pkl', 'rb') as pkl:\n",
    "    glove = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the 300 D array for 'python':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['python'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.68621  , -0.21032  ,  0.30084  , -0.20957  , -0.14055  ,\n",
       "        0.16589  , -0.063815 ,  0.0059568, -0.2608   ,  0.088066 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['python'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some of the methods below, we also need the word frequencies estimated from the corpus. As we currently don't have this available for the GloVe pretrained vectors / Common Crawl corpus, we use the `wordfreq` package (https://github.com/LuminosoInsight/wordfreq/): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.128613839913648e-06"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq.word_frequency('python', 'en', wordlist='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025703957827688632"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq.word_frequency('and', 'en', wordlist='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict similarity between sentences (STS tasks) based on GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the similarity between two sentences, the word embeddings (using the GloVe word vectors) are combined into a sentence embedding. \n",
    "\n",
    "Similarity is calculate as the cosine similarity of the two sentence embeddings, and the performance is evaluated as the Pearson's coefficient between the predicted scores and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avg-GloVe: unweighted average of GloVe vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple method is to take the unweighted average of the different word vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector_avg(sentence):\n",
    "    \"\"\"Calculate the sentence vector as the mean of the word vectors\"\"\"\n",
    "    \n",
    "    word_vecs = []\n",
    "    for token in sentence:\n",
    "        token = token.lower()\n",
    "        try:\n",
    "            word_vecs.append(np.array(glove[token]))\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return np.array(word_vecs).mean(axis=0)\n",
    "\n",
    "def embed_avg(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the average of the word vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict similarity between two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = sentence_vector_avg(s0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = sentence_vector_avg(s1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76406580625096898"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(v0, v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict similarity for the full set of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vs0 = embed_avg(s0)\n",
    "Vs1 = embed_avg(s1)\n",
    "predicted = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x116911da0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1168f8be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(predicted, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation criterion is the Pearson's coefficient between the predicted scores and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65647903053936174"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(predicted, labels)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Systematically on all STS tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tasks(files, embed_func):\n",
    "\n",
    "    tests = []\n",
    "    scores = []\n",
    "\n",
    "    for f in files:\n",
    "        s0, s1, labels = load_sts(f)\n",
    "        Vs0 = embed_func(s0)\n",
    "        Vs1 = embed_func(s1)\n",
    "        predicted = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])\n",
    "        rp = pearsonr(predicted, labels)[0]\n",
    "\n",
    "        scores.append(rp)\n",
    "        name = f.split('/')[-1].split('.')\n",
    "        tests.append((name[0], name[1]))\n",
    "    \n",
    "    return pd.Series(scores, index=pd.MultiIndex.from_tuples(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset-sts/data/sts/semeval-sts/all/2012.MSRpar.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2012.OnWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2012.SMTeuroparl.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2012.SMTnews.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2013.FNWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2013.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2013.OnWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.deft-forum.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.deft-news.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.images.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.OnWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.tweet-news.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.answers-forums.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.answers-students.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.belief.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.images.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.answer-answer.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.plagiarism.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.postediting.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.question-question.test.tsv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(\"dataset-sts/data/sts/semeval-sts/all/*.test.tsv\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.remove('dataset-sts/data/sts/semeval-sts/all/2015.test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_avg = evaluate_tasks(files, embed_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res_avg.to_frame(name='avg-GloVe') * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2012</th>\n",
       "      <th>MSRpar</th>\n",
       "      <td>43.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>52.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTeuroparl</th>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTnews</th>\n",
       "      <td>46.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>FNWN</th>\n",
       "      <td>36.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>42.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2014</th>\n",
       "      <th>deft-forum</th>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-news</th>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>58.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>54.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet-news</th>\n",
       "      <td>51.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>answers-forums</th>\n",
       "      <td>31.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers-students</th>\n",
       "      <td>63.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belief</th>\n",
       "      <td>38.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>65.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>answer-answer</th>\n",
       "      <td>35.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>58.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagiarism</th>\n",
       "      <td>50.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postediting</th>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-question</th>\n",
       "      <td>47.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg-GloVe\n",
       "2012 MSRpar                  43.8\n",
       "     OnWN                    52.7\n",
       "     SMTeuroparl             44.5\n",
       "     SMTnews                 46.3\n",
       "2013 FNWN                    36.9\n",
       "     headlines               60.5\n",
       "     OnWN                    42.4\n",
       "2014 deft-forum              25.4\n",
       "     deft-news               69.2\n",
       "     headlines               58.7\n",
       "     images                  57.6\n",
       "     OnWN                    54.1\n",
       "     tweet-news              51.9\n",
       "2015 answers-forums          31.6\n",
       "     answers-students        63.8\n",
       "     belief                  38.7\n",
       "     headlines               65.6\n",
       "     images                  65.4\n",
       "2016 answer-answer           35.1\n",
       "     headlines               58.8\n",
       "     plagiarism              50.9\n",
       "     postediting             48.1\n",
       "     question-question       47.4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>46.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>52.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe\n",
       "2012       46.8\n",
       "2013       46.6\n",
       "2014       52.8\n",
       "2015       53.0\n",
       "2016       48.1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe+W: weighted average of GloVe vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Arora *et al.* (2017) paper, a weighted average of the word vectors (smooth inverse frequency weighting) is used based on word frequencies estimated from the commoncrawl dataset. Here, we use the `wordfreq` package (https://github.com/LuminosoInsight/wordfreq/) as alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordfreq\n",
    "\n",
    "def sentence_vector_avg_W(sentence, a=1e-3):\n",
    "    \"\"\"Calculate the sentence vector as the mean of the word vectors\"\"\"\n",
    "    \n",
    "    word_vecs = []\n",
    "    for token in sentence:\n",
    "        token = token.lower()\n",
    "        try:\n",
    "            vw = np.array(glove[token])\n",
    "            freq = wordfreq.word_frequency(token, 'en', wordlist='large')\n",
    "            vw *= a / (a + freq)\n",
    "            word_vecs.append(vw)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return np.array(word_vecs).mean(axis=0)\n",
    "\n",
    "def embed_avg_W(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the average of the word vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg_W(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_avg_W = evaluate_tasks(files, embed_avg_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([res_avg, res_avg_W], keys=['avg-GloVe', 'GloVe+W'], axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2012</th>\n",
       "      <th>MSRpar</th>\n",
       "      <td>43.8</td>\n",
       "      <td>36.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>52.7</td>\n",
       "      <td>58.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTeuroparl</th>\n",
       "      <td>44.5</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTnews</th>\n",
       "      <td>46.3</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>FNWN</th>\n",
       "      <td>36.9</td>\n",
       "      <td>38.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>60.5</td>\n",
       "      <td>64.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>42.4</td>\n",
       "      <td>62.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2014</th>\n",
       "      <th>deft-forum</th>\n",
       "      <td>25.4</td>\n",
       "      <td>30.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-news</th>\n",
       "      <td>69.2</td>\n",
       "      <td>71.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>58.7</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>57.6</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>54.1</td>\n",
       "      <td>68.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet-news</th>\n",
       "      <td>51.9</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>answers-forums</th>\n",
       "      <td>31.6</td>\n",
       "      <td>43.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers-students</th>\n",
       "      <td>63.8</td>\n",
       "      <td>68.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belief</th>\n",
       "      <td>38.7</td>\n",
       "      <td>51.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>65.6</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>65.4</td>\n",
       "      <td>75.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>answer-answer</th>\n",
       "      <td>35.1</td>\n",
       "      <td>44.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>58.8</td>\n",
       "      <td>63.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagiarism</th>\n",
       "      <td>50.9</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postediting</th>\n",
       "      <td>48.1</td>\n",
       "      <td>57.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-question</th>\n",
       "      <td>47.4</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg-GloVe  GloVe+W\n",
       "2012 MSRpar                  43.8     36.9\n",
       "     OnWN                    52.7     58.2\n",
       "     SMTeuroparl             44.5     48.1\n",
       "     SMTnews                 46.3     47.0\n",
       "2013 FNWN                    36.9     38.5\n",
       "     headlines               60.5     64.5\n",
       "     OnWN                    42.4     62.1\n",
       "2014 deft-forum              25.4     30.1\n",
       "     deft-news               69.2     71.7\n",
       "     headlines               58.7     62.0\n",
       "     images                  57.6     76.5\n",
       "     OnWN                    54.1     68.6\n",
       "     tweet-news              51.9     55.5\n",
       "2015 answers-forums          31.6     43.6\n",
       "     answers-students        63.8     68.5\n",
       "     belief                  38.7     51.9\n",
       "     headlines               65.6     69.0\n",
       "     images                  65.4     75.5\n",
       "2016 answer-answer           35.1     44.1\n",
       "     headlines               58.8     63.8\n",
       "     plagiarism              50.9     69.4\n",
       "     postediting             48.1     57.5\n",
       "     question-question       47.4     63.2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>46.8</td>\n",
       "      <td>47.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>46.6</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>52.8</td>\n",
       "      <td>60.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>53.0</td>\n",
       "      <td>61.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>48.1</td>\n",
       "      <td>59.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe  GloVe+W\n",
       "2012       46.8     47.6\n",
       "2013       46.6     55.0\n",
       "2014       52.8     60.7\n",
       "2015       53.0     61.7\n",
       "2016       48.1     59.6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The weighting scheme considerably improves the similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the GloVe+WR method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted average from above, but now combined with a removal of the common components, from Arora *et al.* (2017) (https://openreview.net/pdf?id=SyK00v5xx)\n",
    "\n",
    "The algorithm for sentence embedding (Algorithm 1, page 6, Arora et al. 2017):\n",
    "\n",
    "> **Input** Word embeddings $\\{v_w : w \\in \\mathcal{V}\\}$, a set of sentences $\\mathcal{S}$, parameter $a$ and estimated probabilities $\\{p(w) : w \\in \\mathcal{V}\\}$.  \n",
    "> **Output**: Sentence embeddings $\\{v_s : s \\in \\mathcal{S}\\}$\n",
    ">\n",
    "> 1: **for all** sentence $s$ in $\\mathcal{S}$ **do**  \n",
    "> 2: $ \\phantom{...} v_s \\gets \\frac{1}{|s|} \\sum_{w \\in s}{\\frac{a}{a + p(w)} v_w}$  \n",
    "> 3: **end for**  \n",
    "> 4: Compute the first principal component $u$ of $\\{v_s : s \\in \\mathcal{S}\\}$  \n",
    "> 5: **for all** sentence $s$ in $\\mathcal{S}$ **do**  \n",
    "> 6: $ \\phantom{...} v_s \\gets v_s - u u^T v_s$  \n",
    "> 7: **end for**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted average to obtain the sentence embeddings $v_s$ (lines 1-3 in the algorithm) is the same as above (using `sentence_vector_avg_W`), but now afterwards the full matrix of those vectors is further adapted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "def embed_avg_WR(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the weighted average of the word vectors +\n",
    "    applying subtraction of first principal component projection.\n",
    "    \"\"\"\n",
    "    \n",
    "    # weighted average of word vectors for all sentences\n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg_W(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    X = np.array(values)\n",
    "    \n",
    "    # removal of common component\n",
    "    #pca = PCA(n_components=1).fit(X)\n",
    "    #u = pca.components_#[0]\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0).fit(X)\n",
    "    u = svd.components_[0]\n",
    "    \n",
    "    return X - np.dot(X, np.outer(u, u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to evaluate on all tasks is slightly adapted, as we do the embedding (and thus component removal) on all sentences (both left and right sentences) together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tasks2(files, embed_func):\n",
    "\n",
    "    tests = []\n",
    "    scores = []\n",
    "\n",
    "    for f in files:\n",
    "        s0, s1, labels = load_sts(f)\n",
    "        \n",
    "        # combine left and right sentences, embed, and split again\n",
    "        s0 = np.array(s0)\n",
    "        s1 = np.array(s1)\n",
    "        embedded = embed_func(np.concatenate((s0, s1), axis=0))\n",
    "        Vs0 = embedded[:s0.shape[0]]\n",
    "        Vs1 = embedded[s0.shape[0]:]\n",
    "        \n",
    "        predicted = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])\n",
    "        rp = pearsonr(predicted, labels)[0]\n",
    "\n",
    "        scores.append(rp)\n",
    "        name = f.split('/')[-1].split('.')\n",
    "        tests.append((name[0], name[1]))\n",
    "    \n",
    "    return pd.Series(scores, index=pd.MultiIndex.from_tuples(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_avg_WR = evaluate_tasks(files, embed_avg_WR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([res_avg, res_avg_W, res_avg_WR], keys=['avg-GloVe', 'GloVe+W', 'GloVe+WR'], axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "      <th>GloVe+WR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2012</th>\n",
       "      <th>MSRpar</th>\n",
       "      <td>43.8</td>\n",
       "      <td>36.9</td>\n",
       "      <td>28.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>52.7</td>\n",
       "      <td>58.2</td>\n",
       "      <td>68.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTeuroparl</th>\n",
       "      <td>44.5</td>\n",
       "      <td>48.1</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTnews</th>\n",
       "      <td>46.3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>49.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>FNWN</th>\n",
       "      <td>36.9</td>\n",
       "      <td>38.5</td>\n",
       "      <td>43.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>60.5</td>\n",
       "      <td>64.5</td>\n",
       "      <td>70.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>42.4</td>\n",
       "      <td>62.1</td>\n",
       "      <td>78.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2014</th>\n",
       "      <th>deft-forum</th>\n",
       "      <td>25.4</td>\n",
       "      <td>30.1</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-news</th>\n",
       "      <td>69.2</td>\n",
       "      <td>71.7</td>\n",
       "      <td>72.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>58.7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>57.6</td>\n",
       "      <td>76.5</td>\n",
       "      <td>82.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>54.1</td>\n",
       "      <td>68.6</td>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet-news</th>\n",
       "      <td>51.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>68.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>answers-forums</th>\n",
       "      <td>31.6</td>\n",
       "      <td>43.6</td>\n",
       "      <td>61.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers-students</th>\n",
       "      <td>63.8</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belief</th>\n",
       "      <td>38.7</td>\n",
       "      <td>51.9</td>\n",
       "      <td>74.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>65.6</td>\n",
       "      <td>69.0</td>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>65.4</td>\n",
       "      <td>75.5</td>\n",
       "      <td>81.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>answer-answer</th>\n",
       "      <td>35.1</td>\n",
       "      <td>44.1</td>\n",
       "      <td>50.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>58.8</td>\n",
       "      <td>63.8</td>\n",
       "      <td>71.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagiarism</th>\n",
       "      <td>50.9</td>\n",
       "      <td>69.4</td>\n",
       "      <td>76.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postediting</th>\n",
       "      <td>48.1</td>\n",
       "      <td>57.5</td>\n",
       "      <td>79.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-question</th>\n",
       "      <td>47.4</td>\n",
       "      <td>63.2</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg-GloVe  GloVe+W  GloVe+WR\n",
       "2012 MSRpar                  43.8     36.9      28.3\n",
       "     OnWN                    52.7     58.2      68.6\n",
       "     SMTeuroparl             44.5     48.1      49.0\n",
       "     SMTnews                 46.3     47.0      49.2\n",
       "2013 FNWN                    36.9     38.5      43.3\n",
       "     headlines               60.5     64.5      70.7\n",
       "     OnWN                    42.4     62.1      78.3\n",
       "2014 deft-forum              25.4     30.1      36.2\n",
       "     deft-news               69.2     71.7      72.2\n",
       "     headlines               58.7     62.0      66.7\n",
       "     images                  57.6     76.5      82.6\n",
       "     OnWN                    54.1     68.6      80.8\n",
       "     tweet-news              51.9     55.5      68.6\n",
       "2015 answers-forums          31.6     43.6      61.9\n",
       "     answers-students        63.8     68.5      72.8\n",
       "     belief                  38.7     51.9      74.2\n",
       "     headlines               65.6     69.0      74.9\n",
       "     images                  65.4     75.5      81.9\n",
       "2016 answer-answer           35.1     44.1      50.1\n",
       "     headlines               58.8     63.8      71.4\n",
       "     plagiarism              50.9     69.4      76.6\n",
       "     postediting             48.1     57.5      79.3\n",
       "     question-question       47.4     63.2      69.3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "      <th>GloVe+WR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>46.8</td>\n",
       "      <td>47.6</td>\n",
       "      <td>48.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>46.6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>52.8</td>\n",
       "      <td>60.7</td>\n",
       "      <td>67.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>53.0</td>\n",
       "      <td>61.7</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>48.1</td>\n",
       "      <td>59.6</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe  GloVe+W  GloVe+WR\n",
       "2012       46.8     47.6      48.8\n",
       "2013       46.6     55.0      64.1\n",
       "2014       52.8     60.7      67.9\n",
       "2015       53.0     61.7      73.2\n",
       "2016       48.1     59.6      69.3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The removal of the common component based on the first singular vector clearly further improves the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try out, instead of using the SVD first singular vector, let's rescale the sentence embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_avg_WR_2(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the weighted average of the word vectors +\n",
    "    applying subtraction of first principal component projection.\n",
    "    \"\"\"\n",
    "    \n",
    "    # weighted average of word vectors for all sentences\n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg_W(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    X = np.array(values)\n",
    "    \n",
    "    # rescale\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_avg_WR_2 = evaluate_tasks(files, embed_avg_WR_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([res_avg, res_avg_W, res_avg_WR, res_avg_WR_2],\n",
    "                keys=['avg-GloVe', 'GloVe+W', 'GloVe+WR', 'GloVe+W+Scale'], axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "      <th>GloVe+WR</th>\n",
       "      <th>GloVe+W+Scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>46.8</td>\n",
       "      <td>47.6</td>\n",
       "      <td>48.8</td>\n",
       "      <td>50.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>46.6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.1</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>52.8</td>\n",
       "      <td>60.7</td>\n",
       "      <td>67.9</td>\n",
       "      <td>68.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>53.0</td>\n",
       "      <td>61.7</td>\n",
       "      <td>73.2</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>48.1</td>\n",
       "      <td>59.6</td>\n",
       "      <td>69.3</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe  GloVe+W  GloVe+WR  GloVe+W+Scale\n",
       "2012       46.8     47.6      48.8           50.1\n",
       "2013       46.6     55.0      64.1           65.0\n",
       "2014       52.8     60.7      67.9           68.5\n",
       "2015       53.0     61.7      73.2           73.4\n",
       "2016       48.1     59.6      69.3           70.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a further test, let's see what the influence is of not learning the SVD on the data to convert, but on training data.\n",
    "\n",
    "Therefore, I converted the embedding functions above into a sklearn-like transformer, which we then apply in a random 10-fold cross-validation setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordembeddings import EmbeddingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = EmbeddingVectorizer(word_vectors=glove, weighted=True, R=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = emb.fit_transform(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21522961, -0.05944209, -0.15008523, ...,  0.00582434,\n",
       "         0.08136623,  0.03971812],\n",
       "       [ 0.20036008,  0.07927201, -0.13354349, ...,  0.03925085,\n",
       "         0.0614967 ,  0.01952908],\n",
       "       [ 0.03445055,  0.03194463,  0.10754277, ...,  0.01129565,\n",
       "        -0.05099302, -0.07987193],\n",
       "       ..., \n",
       "       [-0.04692298, -0.18660976,  0.02979497, ...,  0.18384892,\n",
       "         0.13451208,  0.0519629 ],\n",
       "       [ 0.01919211,  0.04019597,  0.1699589 , ..., -0.06129473,\n",
       "         0.09762889, -0.10718969],\n",
       "       [ 0.23537602, -0.03565443, -0.01905269, ..., -0.07654032,\n",
       "        -0.24171372,  0.04245305]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = []\n",
    "scores = []\n",
    "scores_CV = []\n",
    "\n",
    "for f in files:\n",
    "    s0, s1, labels = load_sts(f)\n",
    "\n",
    "\n",
    "    s0 = np.array(s0)\n",
    "    s1 = np.array(s1)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # on all data\n",
    "    X = np.concatenate((s0, s1), axis=0)\n",
    "    embedded = EmbeddingVectorizer(word_vectors=glove, weighted=True, R=True).fit_transform(X)\n",
    "    Vs0 = embedded[:s0.shape[0]]\n",
    "    Vs1 = embedded[s0.shape[0]:]\n",
    "\n",
    "    predicted = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])\n",
    "    rp = pearsonr(predicted, labels)[0]\n",
    "\n",
    "    # using cross-validation\n",
    "\n",
    "    predicted = []\n",
    "    y = []\n",
    "\n",
    "    for train_index, test_index in kf.split(s0):\n",
    "        #print(train_index, test_index)\n",
    "        X_train0, X_test0 = s0[train_index], s0[test_index]\n",
    "        X_train1, X_test1 = s1[train_index], s1[test_index]\n",
    "\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = np.concatenate((X_train0, X_train1), axis=0)\n",
    "        X_test = np.concatenate((X_test0, X_test1), axis=0)\n",
    "\n",
    "        emb = EmbeddingVectorizer(word_vectors=glove, weighted=True, R=True).fit(X_train)\n",
    "        embedded = emb.transform(X_test)\n",
    "\n",
    "        Vs0 = embedded[:X_test0.shape[0]]\n",
    "        Vs1 = embedded[X_test0.shape[0]:]\n",
    "        pred = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])\n",
    "\n",
    "        predicted.append(pred)\n",
    "        y.append(y_test)\n",
    "\n",
    "    predicted = np.concatenate(predicted)\n",
    "    y = np.concatenate(y)\n",
    "    rp_CV = pearsonr(predicted, y)[0]\n",
    "    \n",
    "    scores.append(rp)\n",
    "    scores_CV.append(rp_CV)\n",
    "    name = f.split('/')[-1].split('.')\n",
    "    tests.append((name[0], name[1]))\n",
    "    \n",
    "res = pd.DataFrame({'all': scores, 'CV': scores_CV}, index=pd.MultiIndex.from_tuples(tests), columns=['all', 'CV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2012</th>\n",
       "      <th>MSRpar</th>\n",
       "      <td>28.3</td>\n",
       "      <td>28.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>68.5</td>\n",
       "      <td>68.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTeuroparl</th>\n",
       "      <td>49.1</td>\n",
       "      <td>49.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTnews</th>\n",
       "      <td>49.7</td>\n",
       "      <td>49.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>FNWN</th>\n",
       "      <td>42.3</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>70.7</td>\n",
       "      <td>70.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>78.5</td>\n",
       "      <td>78.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2014</th>\n",
       "      <th>deft-forum</th>\n",
       "      <td>36.2</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-news</th>\n",
       "      <td>72.2</td>\n",
       "      <td>72.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>66.7</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>82.6</td>\n",
       "      <td>82.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>80.9</td>\n",
       "      <td>80.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet-news</th>\n",
       "      <td>66.2</td>\n",
       "      <td>66.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>answers-forums</th>\n",
       "      <td>62.1</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers-students</th>\n",
       "      <td>72.7</td>\n",
       "      <td>72.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belief</th>\n",
       "      <td>74.3</td>\n",
       "      <td>74.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>74.9</td>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>answer-answer</th>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>71.3</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagiarism</th>\n",
       "      <td>76.6</td>\n",
       "      <td>76.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postediting</th>\n",
       "      <td>79.4</td>\n",
       "      <td>79.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-question</th>\n",
       "      <td>69.3</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         all    CV\n",
       "2012 MSRpar             28.3  28.3\n",
       "     OnWN               68.5  68.5\n",
       "     SMTeuroparl        49.1  49.1\n",
       "     SMTnews            49.7  49.7\n",
       "2013 FNWN               42.3  42.2\n",
       "     headlines          70.7  70.7\n",
       "     OnWN               78.5  78.5\n",
       "2014 deft-forum         36.2  36.2\n",
       "     deft-news          72.2  72.2\n",
       "     headlines          66.7  66.7\n",
       "     images             82.6  82.6\n",
       "     OnWN               80.9  80.9\n",
       "     tweet-news         66.2  66.3\n",
       "2015 answers-forums     62.1  62.0\n",
       "     answers-students   72.7  72.6\n",
       "     belief             74.3  74.3\n",
       "     headlines          74.9  74.9\n",
       "     images             82.0  82.0\n",
       "2016 answer-answer      50.0  50.0\n",
       "     headlines          71.3  71.3\n",
       "     plagiarism         76.6  76.6\n",
       "     postediting        79.4  79.3\n",
       "     question-question  69.3  69.3"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>48.9</td>\n",
       "      <td>48.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>63.8</td>\n",
       "      <td>63.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>67.5</td>\n",
       "      <td>67.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>73.2</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>69.3</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       all    CV\n",
       "2012  48.9  48.9\n",
       "2013  63.8  63.8\n",
       "2014  67.5  67.5\n",
       "2015  73.2  73.2\n",
       "2016  69.3  69.3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "table.dataframe th {\n",
       "  vertical-align: top;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<style type=\"text/css\">\n",
    "table.dataframe th {\n",
    "  vertical-align: top;\n",
    "}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
